---
layout: post
title: "Summer Project (Dark Reaction) Snippet!"
date: 2019-06-09
---

This summer I am working on the [Dark Reaction Project](https://darkreactions.haverford.edu/) with [Sorelle Friedler](http://sorelle.friedler.net/) at [Haverford College](https://www.haverford.edu/). The broad goal of this project is to use machine learning techniques to predict the outcomes of chemistry reaction. I am mainly working on the code side with another student, and there are also a couple of people working on the research side, which focuses on developing and applying interpretability techniques of machine learning model. I would like to briefly share what I have learned and done in the past two weeks:

## Structure Of My Part

I am mainly responsible for rewriting and extracting major functions in the recommendation engine. The reason why we rewrote the entire part is that the existing codebase is a bit messy and not working right now. Originally, all the three parts above (Reaction generators + ML model+ recommendation system) are connected with a MySQL Database. The Database is then connected with GUI, where the chemists can enter data (PH values, compound names and their mass etc), and the entire project is dependent on *Django* framework. These overall set a lot of limitations and inconvenience for usage. That’s why we are starting to rewrite these parts independently from current Database and *Django* so that they can flexibly take any form of argument and machine learning model.

The end goal of the recommendation engine is to recommend the “best” reactions to chemists, which is divided into three parts:

### Part I: Generate Reaction Features.

First, we generate potential reactions based on the combination of various parameters. Some parameters are specific to the compounds that participate in the reaction (inorganic/organic molecule names and their mass). It is assumed that each reaction consists of two inorganic compounds and one organic compound, which overall forms a triple. Other parameters, which we call grid parameters, are specific to the reaction environment (PH values, temperature etc). Since there are only certain values we can choose for each parameter, the combination of these parameters would be finite. We store these potential reactions in a Dataframe, and we also need to expand the Dataframe by adding the descriptors for each compound.These descriptors describe detailed properties of a chemical compound (polarity, surface area etc.), which can be generated by a package called [ChemAxon](https://chemaxon.com/).

### Part II: Run trained models

Then, we need to filter reactions based on the **desired descriptors**, because not all descriptors generated by ChemAxon can be passed through the ML model. But the desired descriptors depend on what ML model we choose. After filtering, we can pass these potential reactions into a trained machine learning model to predict outcomes by assigning them a score in {1, 2, 3, 4}. The success of a reaction is measured by the amount of crystal being generated.  

##### Part III: Recommend Reactions

Last, we can further filter out reactions based on **ML outcome scores** and **mutual information hashing**. We might only want to keep the successful reactions predicted by the model. Then we can rank the reactions based on the [mutual information](https://en.wikipedia.org/wiki/Mutual_information), which measures the amount of addition “information” the new reactions can bring to the existing reactions. This is an interesting concept, which refers to the dependency of two random variables in probability, or the ability to infer the information of another random variable from one random variable.  If the mutual information is small, it means that the new reaction is too similar to the old reactions to give us new insights. Intuitively, mutual information is related to the euclidean distance between reactions on a vector space, where reaction represents a point based on its compounds and outcomes. We probably would further filter reactions based on a convex hull constraint set, which sets limits for combination of different parameters (e.g we can not have a reaction that runs in super high temperature with super low PH value). This is totally decided by chemists and we haven’t worked on this part yet. After all the filtering and ranking, we can get the top ‘k’ reactions and recommend them to the chemists.

## Progress, Challenge, and Future Plan

So far we have finished writing Part I and Part II of the recommendation engine. A postdoc we are working with is finishing up with Part III. We are currently refining the code to make it more readable and efficient.

One major challenge of our work is to deal with the tricks of python data structures. For instance, when we want add descriptors into Dataframe, we need to find a way to add all descriptors at one time, since Dataframe does not allow you to only expand a single row. Another trick about python dictionary is that when we want to add the values of a dictionary into a list, there is no guarantee that the elements in that list will be the same order as the order in the dictionary when I call it. Thus, we need to call the value by key to guarantee certain orders. For instance,  instead of calling *list(experiment.values())*, it is better to call *experiment['compounds']*, where experiment is a dictionary.

Future work in the project may include choosing different machine learning models and techniques, such as neural networks. Currently the project uses SVM in *Wekas*, which is a package written in Java. It has 89% accuracy that beats human chemists, and performs significantly better than most other packages - here is the [paper](https://www.nature.com/articles/nature17439) that describes it. But the fundamental factor that determines the performance is still unknown, which is why interpretability side comes in - try to find ways to learn about science by understanding the patterns revealed by these models.

OK. That’s it. Looking forward to the next level of progress and intellectual discovery!
